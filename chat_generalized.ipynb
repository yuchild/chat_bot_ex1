{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.mayoclinic.org/diseases-conditions/chronic-kidney-disease/symptoms-causes/syc-20354521'\n",
    "def chat_bot(url, user_in):\n",
    "    from newspaper import Article\n",
    "    import random\n",
    "    import string\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    import nltk\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # might not be necessary (machine specific)\n",
    "    import ssl\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    \n",
    "    # Download packages from NLTK\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    \n",
    "    # Get the article\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    article.nlp()\n",
    "    corpus = article.text\n",
    "    \n",
    "    # Tokenization \n",
    "    text = corpus\n",
    "    sent_tokens = nltk.sent_tokenize(text) # convert text to list of sentences\n",
    "    \n",
    "    # create a dictionary (key:value) pair to remove punctuations, use ord to get the ordinal numbers\n",
    "    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "    \n",
    "    def LemNormalize(text):\n",
    "        return nltk.word_tokenize(text.lower().translate(remove_punct_dict))\n",
    "    \n",
    "    \n",
    "    ### INPUT FROM USER ###\n",
    "    user_in = user_in.lower() # make user_in lower case\n",
    "    \n",
    "    \n",
    "    # set chatbot response to any empty string\n",
    "    robo_out = ''\n",
    "\n",
    "    # Append users response to sentence list\n",
    "    sent_tokens.append(user_in)\n",
    "    \n",
    "    # Create a TfidfVectorizer object\n",
    "    tf_vec = TfidfVectorizer(tokenizer = LemNormalize, stop_words = 'english')\n",
    "\n",
    "    # Convert text to a matrix of TF-IDF features\n",
    "    tfidf = tf_vec.fit_transform(sent_tokens)\n",
    "    \n",
    "    # Get measure of similarity (score)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf) # compare user in with all features\n",
    "    \n",
    "    # Get index of the sentence most similar to user's in\n",
    "    idx = vals.argsort()[0][-2] # 0 because list in list, -2 to get the end top score, -1 is the user_in which is most similar\n",
    "\n",
    "    # Reduce dimensionality of vals, to make from list of list to just one list\n",
    "    val_flat = vals.flatten()\n",
    "\n",
    "    # Sort val_flat in ascending order\n",
    "    val_flat.sort()\n",
    "\n",
    "    \n",
    "    ### Get the most similar score to the user_in\n",
    "    score = val_flat[-2] # -1 is the user_in, -2 is the top score\n",
    "    \n",
    "    \n",
    "    # If the score is 0, then there is no text similar to user's response\n",
    "    if (score == 0):\n",
    "        robo_out = robo_out + \" I apologize, I don't understand.\" \n",
    "    else:\n",
    "        robo_out = robo_out + sent_tokens[idx]\n",
    "    \n",
    "    # Remove user_in\n",
    "    sent_tokens.remove(user_in)\n",
    "    \n",
    "    return score, robo_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview\n",
      "\n",
      "Chronic kidney disease, also called chronic kidney failure, describes the gradual loss of kidney function. Score: 0.5068559627834549\n"
     ]
    }
   ],
   "source": [
    "score, robo_out = chat_bot(url, \"What is chronic kidney disease?\")\n",
    "print(robo_out, f'Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diseases and conditions that cause chronic kidney disease include:\n",
      "\n",
      "Type 1 or type 2 diabetes\n",
      "\n",
      "High blood pressure\n",
      "\n",
      "Glomerulonephritis (gloe-mer-u-low-nuh-FRY-tis), an inflammation of the kidney's filtering units (glomeruli)\n",
      "\n",
      "Interstitial nephritis (in-tur-STISH-ul nuh-FRY-tis), an inflammation of the kidney's tubules and surrounding structures\n",
      "\n",
      "Polycystic kidney disease\n",
      "\n",
      "Prolonged obstruction of the urinary tract, from conditions such as enlarged prostate, kidney stones and some cancers\n",
      "\n",
      "Vesicoureteral (ves-ih-koe-yoo-REE-tur-ul) reflux, a condition that causes urine to back up into your kidneys\n",
      "\n",
      "Recurrent kidney infection, also called pyelonephritis (pie-uh-low-nuh-FRY-tis)\n",
      "\n",
      "Risk factors\n",
      "\n",
      "Factors that may increase your risk of chronic kidney disease include:\n",
      "\n",
      "Diabetes\n",
      "\n",
      "High blood pressure\n",
      "\n",
      "Heart and blood vessel (cardiovascular) disease\n",
      "\n",
      "Smoking\n",
      "\n",
      "Obesity\n",
      "\n",
      "Being African-American, Native American or Asian-American\n",
      "\n",
      "Family history of kidney disease\n",
      "\n",
      "Abnormal kidney structure\n",
      "\n",
      "Older age\n",
      "\n",
      "Complications\n",
      "\n",
      "Chronic kidney disease can affect almost every part of your body. Score: 0.26578712288780987\n"
     ]
    }
   ],
   "source": [
    "score, robo_out = chat_bot(url, \"What causes kidney disease?\")\n",
    "print(robo_out, f'Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65] The median longevity of mixed-breed dogs, taken as an average of all sizes, is one or more years longer than that of purebred dogs when all breeds are averaged. Score: 0.2920178776892433\n"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Dog'\n",
    "score, robo_out = chat_bot(url, \"Dog sizes?\")\n",
    "print(robo_out, f'Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128] Although new medications may take until 2021 to develop,[183] several of the medications being tested are already approved for other uses or are already in advanced testing. Score: 0.40400438758812446\n"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Coronavirus_disease_2019'\n",
    "score, robo_out = chat_bot(url, \"Medications of the disease?\")\n",
    "print(robo_out, f'Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wuhan, China), animal species or groups of people in disease and virus names to prevent social stigma. Score: 0.21680310861171218\n"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Coronavirus_disease_2019'\n",
    "score, robo_out = chat_bot(url, \"how to prevent covid19?\")\n",
    "print(robo_out, f'Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
